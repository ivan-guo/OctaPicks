{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Static Fight Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n",
    "import csv\n",
    "\n",
    "# Initialize the CSV file for writing\n",
    "with open('ufc_fighters_static.csv', 'w', newline='') as csvfile:\n",
    "    # Define the column headers for the CSV\n",
    "    fieldnames = ['Name', 'Height', 'Reach', 'Stance', 'DOB', 'ID']\n",
    "    \n",
    "    # Initialize the CSV writer\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header row to the CSV\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Generate a list of lowercase alphabets to iterate through\n",
    "    alphabets = list(string.ascii_lowercase)\n",
    "\n",
    "    # Loop through each alphabet letter\n",
    "    for letter in alphabets:\n",
    "        # Fetch the fighter list page for the current alphabet letter\n",
    "        source = requests.get(f'http://www.ufcstats.com/statistics/fighters?char={letter}&page=all').text\n",
    "        soup = BeautifulSoup(source, \"lxml\")\n",
    "\n",
    "        # Loop through each fighter entry on the page\n",
    "        for fighter in soup.find_all('tr', attrs={'class': 'b-statistics__table-row'}):\n",
    "            a_href = fighter.find('a')\n",
    "            \n",
    "            # Check if the fighter entry has a URL\n",
    "            if a_href is not None:\n",
    "                # Fetch the fighter's individual stats page\n",
    "                source2 = requests.get(a_href.get(\"href\")).text\n",
    "                \n",
    "                # Extract the fighter ID from the URL\n",
    "                ID = a_href.get(\"href\").split('/')[-1].strip()\n",
    "                \n",
    "                soup2 = BeautifulSoup(source2, \"lxml\")\n",
    "\n",
    "                # Extract and store the fighter's name\n",
    "                name = soup2.find('span', {'class': 'b-content__title-highlight'}).text.strip()\n",
    "\n",
    "                # Initialize a dictionary to hold the fighter's stats\n",
    "                fighter_stats = {'Name': name, 'ID': ID}\n",
    "\n",
    "                # Extract and store other stats like Height, Reach, Stance, and DOB\n",
    "                stats = soup2.find_all('li', attrs={'class': 'b-list__box-list-item'})\n",
    "                for stat in stats:\n",
    "                    cleaned_stat = [string.strip() for string in stat.text.split(\":\")]\n",
    "                    if len(cleaned_stat) > 1:\n",
    "                        key = cleaned_stat[0]\n",
    "                        value = cleaned_stat[1]\n",
    "                        fighter_stats[key] = value\n",
    "\n",
    "                # Write the collected stats to the CSV file\n",
    "                writer.writerow(fighter_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
